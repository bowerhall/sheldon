# Sheldon Configuration
#
# Local dev: cp .env.example .env && fill in values
# Deployment: Import to Doppler (see docs/deployment.md)

# =============================================================================
# REQUIRED
# =============================================================================

TELEGRAM_TOKEN=your-telegram-bot-token
KIMI_API_KEY=your-kimi-api-key
TZ=UTC

# =============================================================================
# OPTIONAL - LLM Provider
# Default is Kimi. Uncomment to use Claude or OpenAI instead.
# =============================================================================

# LLM_PROVIDER=claude
# LLM_MODEL=claude-sonnet-4-20250514
# ANTHROPIC_API_KEY=your-anthropic-api-key

# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o
# OPENAI_API_KEY=your-openai-api-key

# =============================================================================
# OPTIONAL - Coder LLM
# Uses KIMI_API_KEY by default. Set NVIDIA_API_KEY for free tier access.
# =============================================================================

# NVIDIA_API_KEY=your-nvidia-api-key

# =============================================================================
# OPTIONAL - Git Integration
# For coder to push code to GitHub
# =============================================================================

# GIT_TOKEN=your-github-pat
# GIT_USER_NAME=Sheldon
# GIT_USER_EMAIL=sheldon@example.com
# GIT_ORG_URL=https://github.com/your-org

# =============================================================================
# OPTIONAL - Alert Chat ID
# Where to send budget warnings and error alerts
# Check-ins are now handled via the cron system (just ask Sheldon to check in)
# =============================================================================

# HEARTBEAT_CHAT_ID=your-telegram-chat-id

# =============================================================================
# OPTIONAL - Extractor
# In deployment: uses local Ollama (qwen2:0.5b) - zero API cost
# For local dev: defaults to Kimi if not set
# =============================================================================

# EXTRACTOR_PROVIDER=ollama
# EXTRACTOR_BASE_URL=http://localhost:11434
# EXTRACTOR_MODEL=qwen2:0.5b
